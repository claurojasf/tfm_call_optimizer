{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Mistral-7B Response:\n",
      "Tell me about Mistral model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ‚úÖ Hugging Face API Key (Ensure it's set in your environment variables)\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "if not HUGGINGFACE_API_KEY:\n",
    "    raise ValueError(\"‚ùå Missing Hugging Face API Key. Set it as HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# ‚úÖ Load Mistral-7B-Instruct-v0.2 via API Inference\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",  # ‚úÖ Updated model\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 2048},\n",
    "    huggingfacehub_api_token=HUGGINGFACE_API_KEY\n",
    ")\n",
    "\n",
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"Tell me about Mistral model.\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(\"\\nüîπ Mistral-7B Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you show me the top 10 best movies of all time? sure! here are the top 10 movies of all time, based on their average rating on IMDb and Rotten Tomatoes, as well as their box office success:\n",
      "\n",
      "1. The Godfather (1972) - IMDb: 9.2, Rotten Tomatoes: 97%, Box Office: $245 million\n",
      "2. The Dark Knight (2008) - IMDb: 9.0, Rotten Tomatoes: 94%, Box Office: $1.004 billion\n",
      "3. 12 Angry Men (1957) - IMDb: 8.9, Rotten Tomatoes: 100%, Box Office: $2.9 million\n",
      "4. Schindler's List (1993) - IMDb: 8.9, Rotten Tomatoes: 97%, Box Office: $322.1 million\n",
      "5. Pulp Fiction (1994) - IMDb: 8.9, Rotten Tomatoes: 92%, Box Office: $213.9 million\n",
      "6. The Lord of the Rings: The Return of the King (2003) - IMDb: 8.9, Rotten Tomatoes: 93%, Box Office: $1.119 billion\n",
      "7. The Good, the Bad and the Ugly (1966) - IMDb: 8.8, Rotten Tomatoes: 97%, Box Office: $25.1 million\n",
      "8. The Lord of the Rings: The Fellowship of the Ring (2001) - IMDb: 8.9, Rotten Tomatoes: 91%, Box Office: $871.5 million\n",
      "9. The Lord of the Rings: The Two Towers (2002) - IMDb: 8.7, Rotten Tomatoes: 95%, Box Office: $926 million\n",
      "10. The Lord of the Rings: The Hobbit: An Unexpected Journey (2012) - IMDb: 8.0, Rotten Tomatoes: 64%, Box Office: $1.021 billion\n",
      "\n",
      "These movies have been critically acclaimed and have left a lasting impact on cinema. They span various genres, including drama, action, and fantasy, and showcase some of the best storytelling, performances, and filmmaking techniques in history. Enjoy watching!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"can you show me the top 10 best movies of all time?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you name the top 10 soccer players in history? Here's a list of top 10 soccer players in history, based on their skills, achievements, and impact on the sport:\n",
      "\n",
      "1. **Pel√© (Brazil)**: A three-time World Cup winner (1958, 1962, 1970), Pel√© is widely regarded as the greatest soccer player of all time. He scored a record 1,279 goals in 1,363 games, including unofficial friendlies.\n",
      "\n",
      "2. **Diego Maradona (Argentina)**: Maradona led Argentina to World Cup glory in 1986 and is famous for his dribbling skills, passing, vision, and playmaking. He was named FIFA Player of the 20th Century alongside Pel√© in 2000.\n",
      "\n",
      "3. **Lionel Messi (Argentina)**: Messi has won a record seven Ballon d'Or awards and is the all-time leading scorer for both Barcelona and the Argentina national team. He's known for his dribbling, passing, finishing, and playmaking abilities.\n",
      "\n",
      "4. **Cristiano Ronaldo (Portugal)**: Ronaldo has won five Ballon d'Or awards and is the all-time leading scorer in the UEFA Champions League. He's known for his finishing, heading, and work ethic.\n",
      "\n",
      "5. **Johan Cruyff (Netherlands)**: Cruyff was a key figure in the Dutch \"Total Football\" system and won three Ballon d'Or awards. He's known for his vision, passing, and dribbling skills.\n",
      "\n",
      "6. **Zinedine Zidane (France)**: Zidane won the 1998 World Cup and the 2000 European Championship with France. He's known for his vision, passing, dribbling, and heading ability.\n",
      "\n",
      "7. **Franz Beckenbauer (Germany)**: Known as \"Der Kaiser,\" Beckenbauer won the World Cup as a player in 1974 and as a manager in 1990. He's known for his leadership, passing, and tackling abilities.\n",
      "\n",
      "8. **Alfredo Di St√©fano (Argentina/Spain)**: Di St√©fano was a key player in Real Madrid's five consecutive European Cup wins from 1956 to 1960. He's known for his goal-scoring ability, passing, and playmaking.\n",
      "\n",
      "9. **George Best (Northern Ireland)**: Best was known for his dribbling, passing, and finishing abilities. He won the European Cup with Manchester United in 1968 and was named the European Footballer of the Year in 1968.\n",
      "\n",
      "10. **Roberto Baggio (Italy)**: Baggio is known for his dribbling, passing, and finishing abilities. He won the 1993 FIFA World Cup Golden Ball and was named the 1993 European Footballer of the Year.\n",
      "\n",
      "These rankings can be subjective and depend on personal preferences, but these players are consistently recognized as some of the greatest in history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"can you name the top 10 soccer players in history?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"give me a short summary of the little prince book.\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"how can i learn python quikly?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"How does DeepSeek-R1 differ from Mistral-7B?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
