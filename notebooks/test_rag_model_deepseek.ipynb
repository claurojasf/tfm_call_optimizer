{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Claudio\\AppData\\Local\\Temp\\ipykernel_12088\\2885508344.py:18: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ DeepSeek-R1 Response:\n",
      "tell me about DeeepSeek. What is it?\n",
      "\n",
      "DeepSeek is a large language model developed by the DeepSeek AI team, a research organization focused on advancing AI capabilities. Here are some key points about DeepSeek:\n",
      "\n",
      "1. **Size**: DeepSeek is a large language model, with versions ranging from 7 billion to 65 billion parameters. The larger models are designed to understand, generate, and interact with text more effectively.\n",
      "\n",
      "2. **Capabilities**: DeepSeek is trained on a vast amount of text data from the internet, allowing it to:\n",
      "   - Answer questions and provide explanations on a wide range of topics.\n",
      "   - Generate creative content like poems, stories, and code.\n",
      "   - Help with brainstorming ideas and solving problems.\n",
      "   - Engage in conversations on various subjects.\n",
      "\n",
      "3. **Multilingual Support**: DeepSeek is designed to understand and generate text in multiple languages, although its performance may vary across languages.\n",
      "\n",
      "4. **Safety and Responsibility**: DeepSeek is trained to be safe, respectful, and honest. It's designed to decline inappropriate requests and avoid generating harmful, biased, or misleading outputs. However, it's essential to use such models responsibly and critically evaluate their responses.\n",
      "\n",
      "5. **Accessibility**: DeepSeek is available through an API, making it accessible for developers to integrate into their applications. It also offers a web interface for direct interaction.\n",
      "\n",
      "6. **Research and Development**: DeepSeek AI is committed to advancing the field of AI, and they regularly release updates and improvements to their models.\n",
      "\n",
      "For the most accurate and up-to-date information, I recommend checking the official DeepSeek AI website or their documentation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ‚úÖ Hugging Face API Key (Ensure it's set in your environment variables)\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "if not HUGGINGFACE_API_KEY:\n",
    "    raise ValueError(\"‚ùå Missing Hugging Face API Key. Set it as HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "\n",
    "# ‚úÖ Load DeepSeek-R1 via API Inference\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"deepseek-ai/DeepSeek-R1\",  # Model name\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 2048},\n",
    "    huggingfacehub_api_token=HUGGINGFACE_API_KEY\n",
    ")\n",
    "\n",
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"tell me about DeeepSeek.\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(\"\\nüîπ DeepSeek-R1 Response:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you show me the top 10 best movies of all time? sure! here are the top 10 movies of all time, based on their average rating on IMDb and Rotten Tomatoes, as well as their box office success:\n",
      "\n",
      "1. The Godfather (1972) - IMDb: 9.2, Rotten Tomatoes: 97%, Box Office: $245 million\n",
      "2. The Dark Knight (2008) - IMDb: 9.0, Rotten Tomatoes: 94%, Box Office: $1.004 billion\n",
      "3. 12 Angry Men (1957) - IMDb: 8.9, Rotten Tomatoes: 100%, Box Office: $2.9 million\n",
      "4. Schindler's List (1993) - IMDb: 8.9, Rotten Tomatoes: 97%, Box Office: $322.1 million\n",
      "5. Pulp Fiction (1994) - IMDb: 8.9, Rotten Tomatoes: 92%, Box Office: $213.9 million\n",
      "6. The Lord of the Rings: The Return of the King (2003) - IMDb: 8.9, Rotten Tomatoes: 93%, Box Office: $1.119 billion\n",
      "7. The Good, the Bad and the Ugly (1966) - IMDb: 8.8, Rotten Tomatoes: 97%, Box Office: $25.1 million\n",
      "8. The Lord of the Rings: The Fellowship of the Ring (2001) - IMDb: 8.9, Rotten Tomatoes: 91%, Box Office: $871.5 million\n",
      "9. The Lord of the Rings: The Two Towers (2002) - IMDb: 8.7, Rotten Tomatoes: 95%, Box Office: $926 million\n",
      "10. The Lord of the Rings: The Hobbit: An Unexpected Journey (2012) - IMDb: 8.0, Rotten Tomatoes: 64%, Box Office: $1.021 billion\n",
      "\n",
      "These movies have been critically acclaimed and have left a lasting impact on cinema. They span various genres, including drama, action, and fantasy, and showcase some of the best storytelling, performances, and filmmaking techniques in history. Enjoy watching!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"can you show me the top 10 best movies of all time?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you name the top 10 soccer players in history? Here's a list of top 10 soccer players in history, based on their skills, achievements, and impact on the sport:\n",
      "\n",
      "1. **Pel√© (Brazil)**: A three-time World Cup winner (1958, 1962, 1970), Pel√© is widely regarded as the greatest soccer player of all time. He scored a record 1,279 goals in 1,363 games, including unofficial friendlies.\n",
      "\n",
      "2. **Diego Maradona (Argentina)**: Maradona led Argentina to World Cup glory in 1986 and is famous for his dribbling skills, passing, vision, and playmaking. He was named FIFA Player of the 20th Century alongside Pel√© in 2000.\n",
      "\n",
      "3. **Lionel Messi (Argentina)**: Messi has won a record seven Ballon d'Or awards and is the all-time leading scorer for both Barcelona and the Argentina national team. He's known for his dribbling, passing, finishing, and playmaking abilities.\n",
      "\n",
      "4. **Cristiano Ronaldo (Portugal)**: Ronaldo has won five Ballon d'Or awards and is the all-time leading scorer in the UEFA Champions League. He's known for his finishing, heading, and work ethic.\n",
      "\n",
      "5. **Johan Cruyff (Netherlands)**: Cruyff was a key figure in the Dutch \"Total Football\" system and won three Ballon d'Or awards. He's known for his vision, passing, and dribbling skills.\n",
      "\n",
      "6. **Zinedine Zidane (France)**: Zidane won the 1998 World Cup and the 2000 European Championship with France. He's known for his vision, passing, dribbling, and heading ability.\n",
      "\n",
      "7. **Franz Beckenbauer (Germany)**: Known as \"Der Kaiser,\" Beckenbauer won the World Cup as a player in 1974 and as a manager in 1990. He's known for his leadership, passing, and tackling abilities.\n",
      "\n",
      "8. **Alfredo Di St√©fano (Argentina/Spain)**: Di St√©fano was a key player in Real Madrid's five consecutive European Cup wins from 1956 to 1960. He's known for his goal-scoring ability, passing, and playmaking.\n",
      "\n",
      "9. **George Best (Northern Ireland)**: Best was known for his dribbling, passing, and finishing abilities. He won the European Cup with Manchester United in 1968 and was named the European Footballer of the Year in 1968.\n",
      "\n",
      "10. **Roberto Baggio (Italy)**: Baggio is known for his dribbling, passing, and finishing abilities. He won the 1993 FIFA World Cup Golden Ball and was named the 1993 European Footballer of the Year.\n",
      "\n",
      "These rankings can be subjective and depend on personal preferences, but these players are consistently recognized as some of the greatest in history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"can you name the top 10 soccer players in history?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me a short summary of the little prince book. I should be able to understand it in 5 minutes.\n",
      "\n",
      "Sure, here's a brief summary of \"The Little Prince\" by Antoine de Saint-Exup√©ry:\n",
      "\n",
      "The story begins with a pilot who has crashed in the Sahara desert. As he tries to repair his plane, he meets a young boy, the Little Prince, who has come to Earth from his tiny home planet, where he lives alone with a single rose. The Little Prince has left his planet to explore the universe, and he meets various adults on different planets, each of whom represents a different aspect of human nature or society.\n",
      "\n",
      "On Earth, the Little Prince meets a Fox who teaches him about the importance of forming relationships and the dangers of becoming too attached. The Fox says, \"You become responsible, forever, for what you have tamed.\" The Little Prince also meets a Snake, who offers to help him return to his home planet.\n",
      "\n",
      "The Little Prince's journey is a metaphor for the human experience, exploring themes of love, loss, and the meaning of life. The story is told through the eyes of the pilot, who comes to care deeply for the Little Prince and is heartbroken when he leaves Earth.\n",
      "\n",
      "In the end, the pilot finds the Little Prince's body in the desert, along with a note from the Snake saying that he has taken the Little Prince back to his home planet. The pilot is devastated but finds comfort in the knowledge that the Little Prince is happy and safe.\n",
      "\n",
      "Throughout the story, Saint-Exup√©ry explores the complexities of human nature, and the importance of maintaining a childlike sense of wonder and imagination in the face of the mundane world.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"give me a short summary of the little prince book.\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how can i learn python quikly? Here's a structured approach to help you learn Python quickly:\n",
      "\n",
      "1. **Choose a Learning Resource:**\n",
      "   - Codecademy's Python course (https://www.codecademy.com/learn/learn-python-3)\n",
      "   - Automate the Boring Stuff with Python (https://automatetheboringstuff.com/)\n",
      "   - Python.org's Beginner's Guide (https://docs.python.org/3/tutorial/)\n",
      "   - Real Python (https://realpython.com/)\n",
      "   - Udemy, Coursera, or edX for structured courses\n",
      "\n",
      "2. **Learn the Basics:**\n",
      "   - Python syntax and data types (Numbers, Strings, Lists, Tuples, Sets, Dictionaries)\n",
      "   - Variables and operators (+, -, *, /, %, **, //, ==, !=, <, >, <=, >=, and, or, not)\n",
      "   - Control structures (if, elif, else, while, for, break, continue, pass)\n",
      "   - Functions (def, return, arguments, parameters, *args, **kwargs)\n",
      "\n",
      "3. **Build Projects:**\n",
      "   - Start with simple projects to apply what you've learned. Here are some ideas:\n",
      "     - Temperature converter (Fahrenheit to Celsius, or vice versa)\n",
      "     - Guess the number game\n",
      "     - Hangman game\n",
      "     - To-do list manager\n",
      "     - Simple calculator\n",
      "     - Mad Libs-style story generator\n",
      "\n",
      "4. **Learn Intermediate Concepts:**\n",
      "   - Modules and packages (import, from, as, __init__.py)\n",
      "   - Error handling (try, except, finally, raise)\n",
      "   - File I/O (open, read, write, with)\n",
      "   - Regular expressions (re module)\n",
      "   - Working with dates and time (datetime module)\n",
      "   - Working with data (csv, json, pandas)\n",
      "\n",
      "5. **Expand Your Knowledge:**\n",
      "   - Explore Python's standard library and third-party packages (NumPy, Pandas, Matplotlib, Django, Flask, etc.)\n",
      "   - Learn about web scraping, data analysis, machine learning, or web development with Python\n",
      "   - Contribute to open-source projects on GitHub\n",
      "\n",
      "6. **Practice Coding Daily:**\n",
      "   - Websites like LeetCode, HackerRank, Exercism, and Codewars offer Python coding challenges\n",
      "   - Participate in Kaggle competitions for hands-on data science experience\n",
      "\n",
      "7. **Join the Python Community:**\n",
      "   - Participate in forums like StackOverflow, Reddit (r/learnpython, r/Python), or Dev.to to ask questions, share your work, and learn from others\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"how can i learn python quikly?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does DeepSeek-R1 differ from Mistral-7B? DeepSeek-R1 and Mistral-7B are both large language models developed using similar transformer architecture. However, they have some key differences:\n",
      "\n",
      "1. **Development Team and Origin**:\n",
      "   - DeepSeek-R1 is developed by the DeepSeek AI team, a collaboration between researchers from various institutions.\n",
      "   - Mistral AI developed Mistral-7B, a French AI startup.\n",
      "\n",
      "2. **Training Data**:\n",
      "   - DeepSeek-R1 is trained on a diverse dataset including books, websites, and code, with a focus on scientific and academic content.\n",
      "   - Mistral-7B is trained on a mix of public data from the internet, including webpages, books, and code.\n",
      "\n",
      "3. **Model Size and Parameters**:\n",
      "   - DeepSeek-R1 is a 12 billion parameter model.\n",
      "   - Mistral-7B is a 7 billion parameter model.\n",
      "\n",
      "4. **Performance and Capabilities**:\n",
      "   - DeepSeek-R1 shows strong performance in tasks that require understanding and generation of scientific and mathematical content.\n",
      "   - Mistral-7B excels in understanding and generation of general text, including creative writing and coding tasks.\n",
      "\n",
      "5. ** Licensing and Access**:\n",
      "   - DeepSeek-R1 is released under a non-commercial license, making it accessible for research and educational purposes.\n",
      "   - Mistral-7B is available through a commercial license, with various pricing tiers for different use cases.\n",
      "\n",
      "6. **Instruction Following**:\n",
      "   - DeepSeek-R1 is designed to follow instructions and complete tasks based on given prompts.\n",
      "   - Mistral-7B also demonstrates strong instruction following capabilities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example Query (Question Answering)\n",
    "query = \"How does DeepSeek-R1 differ from Mistral-7B?\"\n",
    "response = llm.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
