{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcripciones a embeddings y almacenamiento en BBDD vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Claudio\\tfm_call_optimizer\\venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "C:\\Users\\Claudio\\AppData\\Local\\Temp\\ipykernel_25544\\3414628912.py:28: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  huggingface_embeddings = HuggingFaceBgeEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processed and stored 14 chunks for call_0001.txt\n",
      "‚úÖ Processed and stored 6 chunks for call_0003.txt\n",
      "‚úÖ Processed and stored 7 chunks for call_0004.txt\n",
      "‚úÖ Processed and stored 6 chunks for call_0006.txt\n",
      "‚úÖ Processed and stored 7 chunks for call_0007.txt\n",
      "‚úÖ Processed and stored 10 chunks for call_0008.txt\n",
      "üöÄ All call transcriptions stored in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone  # ‚úÖ Correct import for Pinecone\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ‚úÖ Initialize Pinecone Client\n",
    "pinecone_client = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# ‚úÖ Ensure the correct Pinecone index name is set\n",
    "index_name = os.getenv(\"PINECONE_INDEX_V3\")  # ‚úÖ Updated to use the correct index variable\n",
    "if not index_name:\n",
    "    raise ValueError(\"‚ùå PINECONE_INDEX_V3 is not set. Check your .env file.\")\n",
    "\n",
    "# ‚úÖ Ensure the index exists before using it\n",
    "existing_indexes = [idx[\"name\"] for idx in pinecone_client.list_indexes()]\n",
    "if index_name not in existing_indexes:\n",
    "    raise ValueError(f\"‚ùå Index '{index_name}' does not exist in Pinecone. Please create it first.\")\n",
    "\n",
    "# ‚úÖ Initialize Pinecone Index\n",
    "index = pinecone_client.Index(index_name)\n",
    "\n",
    "# ‚úÖ Initialize the Hugging Face Embeddings model\n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# ‚úÖ Define text splitter for chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \",\", \";\", \" \"], \n",
    "    chunk_size=350,  # ‚úÖ Adjusted for better segmentation of varied call lengths\n",
    "    chunk_overlap=75,  # ‚úÖ Slightly reduced overlap to avoid too much redundancy\n",
    "    length_function=len,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "# üìÇ Path to full call transcriptions\n",
    "ruta_docs = r\"C:\\Users\\Claudio\\tfm_call_optimizer\\transcripciones_prueba\"\n",
    "txt_files = [f for f in os.listdir(ruta_docs) if f.endswith(\".txt\")]\n",
    "\n",
    "if not txt_files:\n",
    "    print(\"‚ö† No .txt files found in the directory! Check the path.\")\n",
    "\n",
    "for filename in txt_files:\n",
    "    file_path = os.path.join(ruta_docs, filename)\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # ‚úÖ Combine entire call transcription into a single document\n",
    "    full_transcription = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # ‚úÖ Split the full call into chunks for embedding\n",
    "    chunks = text_splitter.split_text(full_transcription)\n",
    "\n",
    "    # ‚úÖ Extract call ID from filename\n",
    "    call_id = filename.replace(\".txt\", \"\")  # E.g., \"call_004\"\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        embedding = huggingface_embeddings.embed_query(chunk)\n",
    "        vector_id = f\"{call_id}_chunk_{i+1:03}\"  # ‚úÖ Unique ID for each call chunk\n",
    "\n",
    "        # ‚úÖ Store call transcription chunks with metadata\n",
    "        index.upsert([\n",
    "            (\n",
    "                vector_id,\n",
    "                embedding,\n",
    "                {\n",
    "                    \"call_id\": call_id,  # ‚úÖ Matches full call ID\n",
    "                    \"chunk_id\": f\"{i+1:03}\",  # ‚úÖ Sequential chunk numbering\n",
    "                    \"filename\": filename,  # ‚úÖ Correct filename stored\n",
    "                    \"text\": chunk  # ‚úÖ Store actual transcription text\n",
    "                }\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    print(f\"‚úÖ Processed and stored {len(chunks)} chunks for {filename}\")\n",
    "\n",
    "print(\"üöÄ All call transcriptions stored in Pinecone!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
